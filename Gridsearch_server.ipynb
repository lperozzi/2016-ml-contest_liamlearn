{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 5.1.0\n",
      "\n",
      "numpy 1.11.1\n",
      "scipy 0.18.0\n",
      "matplotlib 1.5.1\n",
      "seaborn 0.7.1\n",
      "sklearn 0.18\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)\n",
      "system     : Darwin\n",
      "release    : 16.1.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : db0162ae88094a468d0c24924737999d98a07dba\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,matplotlib,seaborn,sklearn -g\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'data/facies_vectors.csv'\n",
    "training_data = pd.read_csv(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import sklearn.pipeline\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "import sklearn.grid_search\n",
    "from sklearn import metrics\n",
    "\n",
    "clf1 = KNeighborsClassifier()\n",
    "clf2 = GaussianNB()\n",
    "clf3 = SVC()\n",
    "clf4 = DecisionTreeClassifier()\n",
    "clf5 = RandomForestClassifier()\n",
    "clf6 = GradientBoostingClassifier()\n",
    "\n",
    "s_scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [('kNN', clf1)]\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "\n",
    "### gridsearchCV\n",
    "start = time()\n",
    "parameters = dict(kNN__n_neighbors=[2,5,10,15,20],\n",
    "              kNN__weights=['uniform','distance'],\n",
    "              kNN__algorithm=['ball_tree', 'kd_tree', 'brute'],    \n",
    "              kNN__leaf_size=[10,30,50],\n",
    "              kNN__p=[1,2,5],\n",
    "              kNN__metric=['cityblock', 'euclidean', 'l1', 'l2', 'manhattan'],\n",
    "              kNN__n_jobs=[-1])\n",
    "\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline, param_grid=parameters, scoring='f1',cv=10, n_jobs=-1)\n",
    "cv = cv.fit(X_train, y_train)\n",
    "print(cv.best_score_)\n",
    "print(cv.best_params_)\n",
    "print(cv.best_estimator_)\n",
    "print('temps: {:.2f}'.format(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB (pas de grid search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [('standardscaler', s_scaler),\n",
    "        ('SVC', clf3)]\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "\n",
    "### gridsearchCV\n",
    "start = time()\n",
    "parameters = dict(SVC__C=[0.1, 1 , 10, 100, 1000],\n",
    "              SVC__kernel=['rbf','linear'],\n",
    "              SVC__gamma=[0.0001, 0.001, 0.01, 0.1, 1, 10])\n",
    "\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline, param_grid=parameters, scoring='f1',cv=10, n_jobs=-1)\n",
    "cv = cv.fit(X_train, y_train)\n",
    "print(cv.best_score_)\n",
    "print(cv.best_params_)\n",
    "print(cv.best_estimator_)\n",
    "print('temps: {:.2f}'.format(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-563af6de6dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "steps = [('decision_tree', clf4)]\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "\n",
    "### gridsearchCV\n",
    "start = time()\n",
    "parameters = dict(decision_tree__criterion=['gini','entropy'],\n",
    "              decision_tree__splitter=['best','random'],\n",
    "              decision_tree__max_features=['sqrt',1.0],\n",
    "              decision_tree__max_depth=[2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
    "              decision_tree__min_samples_split=[2,  6, 10, 14, 18, 22, 26, 30, 34, 38],\n",
    "              decision_tree__min_samples_leaf=[1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline, param_grid=parameters, scoring='f1',cv=10, n_jobs=-1)\n",
    "cv = cv.fit(X_train, y_train)\n",
    "print(cv.best_score_)\n",
    "print(cv.best_params_)\n",
    "print(cv.best_estimator_)\n",
    "print('temps: {:.2f}'.format(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [('random_forest', clf5)]\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "\n",
    "### gridsearchCV\n",
    "start = time()\n",
    "parameters = dict(random_forest__n_estimators=[ 10, 50, 100,  500],\n",
    "              random_forest__criterion=['gini','entropy'],\n",
    "              random_forest__max_features=['sqrt',1.0],\n",
    "              random_forest__max_depth=[5, 10, 15],\n",
    "              random_forest__min_samples_split=[15, 30, 45],\n",
    "              random_forest__min_samples_leaf=[1, 5, 10],\n",
    "              random_forest__n_jobs=[-1])\n",
    "\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline, param_grid=parameters, scoring='f1',cv=10, n_jobs=-1)\n",
    "cv = cv.fit(X_train, y_train)\n",
    "print(cv.best_score_)\n",
    "print(cv.best_params_)\n",
    "print(cv.best_estimator_)\n",
    "print('temps: {:.2f}'.format(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [('gradient_boosting', clf6)]\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "\n",
    "### gridsearchCV\n",
    "start = time()\n",
    "parameters = dict(gradient_boosting__n_estimators=[ 10, 50, 100, 200],\n",
    "              gradient_boosting__learning_rate=[0.01, 0.1, 1,2],\n",
    "              gradient_boosting__loss=['deviance', 'exponential'],\n",
    "              gradient_boosting__max_features=['sqrt',1.0],\n",
    "              gradient_boosting__max_depth=[5, 10, 15],\n",
    "              gradient_boosting__min_samples_split=[15, 30, 45],\n",
    "              gradient_boosting__min_samples_leaf=[1, 5, 10],\n",
    "              gradient_boosting__subsample=[0.2, 0.5, 1.0])\n",
    "\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline, param_grid=parameters, scoring='f1',cv=10, n_jobs=-1)\n",
    "cv = cv.fit(X_train, y_train)\n",
    "print(cv.best_score_)\n",
    "print(cv.best_params_)\n",
    "print(cv.best_estimator_)\n",
    "print('temps: {:.2f}'.format(time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import sklearn.pipeline\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "import sklearn.grid_search\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=seed)\n",
    "train = np.zeros((X_train.shape[0], X_train.shape[1]+1))\n",
    "columns_name = list(training_data.ix[:, 30:].columns)\n",
    "\n",
    "train[:,:-1] = X_train\n",
    "train[:,-1] = y_train\n",
    "train = pd.DataFrame(train,columns=columns_name)\n",
    "#     print(train.shape)\n",
    "train1 = train.loc[train['Fertility'] == 1]\n",
    "n = len(train1.index)\n",
    "train2 = train.loc[train['Fertility'] == 0]\n",
    "train2 = train2.sample(n=n)\n",
    "train = pd.concat([train1, train2])\n",
    "# print(n)\n",
    "\n",
    "X_train = train.ix[:, :-1]\n",
    "# X_train = X_train.as_matrix().astype(np.float)\n",
    "\n",
    "y_train = train['Fertility']\n",
    "# prepare models\n",
    "models = []\n",
    "\n",
    "# Gridsearch optimised for f1 score\n",
    "models.append(('KNN', KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, metric='euclidean',\n",
    "           metric_params=None, n_jobs=-1, n_neighbors=5, p=1,weights='distance')))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma=0.1, kernel='rbf', C=0.1)))\n",
    "models.append(('DTREE', DecisionTreeClassifier(criterion='entropy', max_depth=5,\n",
    "            max_features='sqrt', min_samples_leaf=3,\n",
    "            min_samples_split=2, splitter='best')))\n",
    "models.append(('RF', RandomForestClassifier( criterion='gini',\n",
    "            max_depth=10, max_features=1.0, min_samples_leaf=5,\n",
    "            min_samples_split=30,\n",
    "            n_estimators=50, n_jobs=-1)))\n",
    "models.append(('GBM', GradientBoostingClassifier(criterion='friedman_mse',\n",
    "              learning_rate=0.1, loss='deviance', max_depth=10,\n",
    "              max_features='sqrt', min_samples_leaf=10,\n",
    "              min_samples_split=2,\n",
    "              n_estimators=200)))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'recall'\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10,random_state=seed)\n",
    "\n",
    "    if name == 'SVM':\n",
    "        sc = preprocessing.StandardScaler()\n",
    "        sc.fit(X_train)\n",
    "        X_train_std = sc.transform(X_train)\n",
    "\n",
    "#         X_test_std = sc.transform(X_test)\n",
    "#     print( name, model)\n",
    "        \n",
    "#     cv_results = cross_val_score(estimator=RandomForestClassifier(),\n",
    "#                          X=X,\n",
    "#                          y=y,\n",
    "#                          cv=kfold,\n",
    "#                          n_jobs=1)\n",
    "        cv_results = cross_val_score(model, X_train_std, y_train, cv = 20, scoring=scoring, n_jobs=-1)\n",
    "    else:\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv = 20, scoring=scoring, n_jobs=-1)\n",
    "        \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "# boxplot algorithm comparison\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results, showmeans=True)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_ylabel('recall')\n",
    "# plt.savefig('fig/algorithm-comparison_f1_recall.pdf', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 5.1.0\n",
      "\n",
      "numpy 1.11.1\n",
      "scipy 0.18.0\n",
      "pandas 0.18.1\n",
      "matplotlib 1.5.1\n",
      "seaborn 0.7.1\n",
      "sklearn 0.18\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# to install watermark magic command: pip install ipyext\n",
    "%load_ext watermark \n",
    "%watermark -v -p numpy,scipy,pandas,matplotlib,seaborn,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset\n",
    "First, we will examine the data set we will use to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "      <td>4149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.503254</td>\n",
       "      <td>2906.867438</td>\n",
       "      <td>64.933985</td>\n",
       "      <td>0.659566</td>\n",
       "      <td>4.402484</td>\n",
       "      <td>13.201066</td>\n",
       "      <td>3.725014</td>\n",
       "      <td>1.518438</td>\n",
       "      <td>0.521852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.474324</td>\n",
       "      <td>133.300164</td>\n",
       "      <td>30.302530</td>\n",
       "      <td>0.252703</td>\n",
       "      <td>5.274947</td>\n",
       "      <td>7.132846</td>\n",
       "      <td>0.896152</td>\n",
       "      <td>0.499720</td>\n",
       "      <td>0.286644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2573.500000</td>\n",
       "      <td>10.149000</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-21.832000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2821.500000</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2932.500000</td>\n",
       "      <td>64.990000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3007.000000</td>\n",
       "      <td>79.438000</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>16.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>361.150000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>19.312000</td>\n",
       "      <td>84.400000</td>\n",
       "      <td>8.094000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Facies        Depth           GR    ILD_log10     DeltaPHI  \\\n",
       "count  4149.000000  4149.000000  4149.000000  4149.000000  4149.000000   \n",
       "mean      4.503254  2906.867438    64.933985     0.659566     4.402484   \n",
       "std       2.474324   133.300164    30.302530     0.252703     5.274947   \n",
       "min       1.000000  2573.500000    10.149000    -0.025949   -21.832000   \n",
       "25%       2.000000  2821.500000    44.730000     0.498000     1.600000   \n",
       "50%       4.000000  2932.500000    64.990000     0.639000     4.300000   \n",
       "75%       6.000000  3007.000000    79.438000     0.822000     7.500000   \n",
       "max       9.000000  3138.000000   361.150000     1.800000    19.312000   \n",
       "\n",
       "             PHIND           PE         NM_M       RELPOS  \n",
       "count  4149.000000  3232.000000  4149.000000  4149.000000  \n",
       "mean     13.201066     3.725014     1.518438     0.521852  \n",
       "std       7.132846     0.896152     0.499720     0.286644  \n",
       "min       0.550000     0.200000     1.000000     0.000000  \n",
       "25%       8.500000          NaN     1.000000     0.277000  \n",
       "50%      12.020000          NaN     2.000000     0.528000  \n",
       "75%      16.050000          NaN     2.000000     0.769000  \n",
       "max      84.400000     8.094000     2.000000     1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 10)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "filename = '../facies_vectors.csv'\n",
    "training_data = pd.read_csv(filename)\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SHRIMPLIN, ALEXANDER D, SHANKLE, LUKE G U, KIMZEY A, CROSS H CATTLE, NOLAN, NEWBY, CHURCHMAN BIBLE]\n",
       "Categories (9, object): [SHRIMPLIN, ALEXANDER D, SHANKLE, LUKE G U, ..., CROSS H CATTLE, NOLAN, NEWBY, CHURCHMAN BIBLE]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Well Name'] = training_data['Well Name'].astype('category')\n",
    "training_data['Formation'] = training_data['Formation'].astype('category')\n",
    "# training_data = training_data[training_data['Well Name'] != 'Recruit F9']\n",
    "training_data['Well Name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PE_mask = training_data['PE'].notnull().values\n",
    "# training_data = training_data[PE_mask]\n",
    "training_data.replace(to_replace=np.nan,value=-99999,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold cross-validation \n",
    "Adapted from [@LukasMosser code](https://gist.github.com/LukasMosser/cd645bad2bdbbb419098ac3ea363f2b3) to fit python 3.5.\n",
    "Doing a cross-validation on each well in order to see how each well perform as a blind text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>GR_cD_step_level_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PHIND_cD_step_level_2</th>\n",
       "      <th>PHIND_cD_step_level_3</th>\n",
       "      <th>PE_cD_step_level_1</th>\n",
       "      <th>PE_cD_step_level_2</th>\n",
       "      <th>PE_cD_step_level_3</th>\n",
       "      <th>GR_entropy_foot10</th>\n",
       "      <th>ILD_log10_entropy_foot10</th>\n",
       "      <th>DeltaPHI_entropy_foot10</th>\n",
       "      <th>PHIND_entropy_foot10</th>\n",
       "      <th>PE_entropy_foot10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.502048</td>\n",
       "      <td>2906.778126</td>\n",
       "      <td>64.938671</td>\n",
       "      <td>0.659477</td>\n",
       "      <td>4.404699</td>\n",
       "      <td>13.203233</td>\n",
       "      <td>-22087.939466</td>\n",
       "      <td>1.518429</td>\n",
       "      <td>0.522082</td>\n",
       "      <td>-0.149963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022784</td>\n",
       "      <td>-0.022784</td>\n",
       "      <td>-22018.571435</td>\n",
       "      <td>-22018.571435</td>\n",
       "      <td>-22018.571435</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.779793</td>\n",
       "      <td>0.870575</td>\n",
       "      <td>0.832670</td>\n",
       "      <td>0.545273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.474337</td>\n",
       "      <td>133.330124</td>\n",
       "      <td>30.295980</td>\n",
       "      <td>0.252675</td>\n",
       "      <td>5.274641</td>\n",
       "      <td>7.131810</td>\n",
       "      <td>41492.164833</td>\n",
       "      <td>0.499720</td>\n",
       "      <td>0.286767</td>\n",
       "      <td>4.924412</td>\n",
       "      <td>...</td>\n",
       "      <td>1.268329</td>\n",
       "      <td>1.268329</td>\n",
       "      <td>41441.902455</td>\n",
       "      <td>41441.902455</td>\n",
       "      <td>41441.902455</td>\n",
       "      <td>0.728947</td>\n",
       "      <td>0.740483</td>\n",
       "      <td>0.720045</td>\n",
       "      <td>0.738475</td>\n",
       "      <td>0.685700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2573.500000</td>\n",
       "      <td>10.149000</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-21.832000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-96.538551</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.212082</td>\n",
       "      <td>-14.212082</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2821.500000</td>\n",
       "      <td>44.740000</td>\n",
       "      <td>0.497034</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2.423000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>-1.202735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272629</td>\n",
       "      <td>-0.272629</td>\n",
       "      <td>-0.231496</td>\n",
       "      <td>-0.231496</td>\n",
       "      <td>-0.231496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2932.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>12.030000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.027656</td>\n",
       "      <td>-0.027656</td>\n",
       "      <td>-0.027656</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3007.000000</td>\n",
       "      <td>79.438000</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>16.057000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.162370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280288</td>\n",
       "      <td>0.280288</td>\n",
       "      <td>0.025482</td>\n",
       "      <td>0.025482</td>\n",
       "      <td>0.025482</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>361.150000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>19.312000</td>\n",
       "      <td>84.400000</td>\n",
       "      <td>8.094000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.034509</td>\n",
       "      <td>...</td>\n",
       "      <td>22.766611</td>\n",
       "      <td>22.766611</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Facies        Depth           GR    ILD_log10     DeltaPHI  \\\n",
       "count  4151.000000  4151.000000  4151.000000  4151.000000  4151.000000   \n",
       "mean      4.502048  2906.778126    64.938671     0.659477     4.404699   \n",
       "std       2.474337   133.330124    30.295980     0.252675     5.274641   \n",
       "min       1.000000  2573.500000    10.149000    -0.025949   -21.832000   \n",
       "25%       2.000000  2821.500000    44.740000     0.497034     1.600000   \n",
       "50%       4.000000  2932.500000    65.000000     0.639000     4.300000   \n",
       "75%       6.000000  3007.000000    79.438000     0.822000     7.500000   \n",
       "max       9.000000  3138.000000   361.150000     1.800000    19.312000   \n",
       "\n",
       "             PHIND            PE         NM_M       RELPOS  \\\n",
       "count  4151.000000   4151.000000  4151.000000  4151.000000   \n",
       "mean     13.203233 -22087.939466     1.518429     0.522082   \n",
       "std       7.131810  41492.164833     0.499720     0.286767   \n",
       "min       0.550000 -99999.000000     1.000000     0.000000   \n",
       "25%       8.500000      2.423000     1.000000     0.277000   \n",
       "50%      12.030000      3.300000     2.000000     0.528000   \n",
       "75%      16.057000      4.000000     2.000000     0.769000   \n",
       "max      84.400000      8.094000     2.000000     1.000000   \n",
       "\n",
       "       GR_cD_step_level_1        ...          PHIND_cD_step_level_2  \\\n",
       "count         4151.000000        ...                    4151.000000   \n",
       "mean            -0.149963        ...                      -0.022784   \n",
       "std              4.924412        ...                       1.268329   \n",
       "min            -96.538551        ...                     -14.212082   \n",
       "25%             -1.202735        ...                      -0.272629   \n",
       "50%              0.013825        ...                      -0.001953   \n",
       "75%              1.162370        ...                       0.280288   \n",
       "max             41.034509        ...                      22.766611   \n",
       "\n",
       "       PHIND_cD_step_level_3  PE_cD_step_level_1  PE_cD_step_level_2  \\\n",
       "count            4151.000000         4151.000000         4151.000000   \n",
       "mean               -0.022784       -22018.571435       -22018.571435   \n",
       "std                 1.268329        41441.902455        41441.902455   \n",
       "min               -14.212082       -99999.000000       -99999.000000   \n",
       "25%                -0.272629           -0.231496           -0.231496   \n",
       "50%                -0.001953           -0.027656           -0.027656   \n",
       "75%                 0.280288            0.025482            0.025482   \n",
       "max                22.766611            1.523253            1.523253   \n",
       "\n",
       "       PE_cD_step_level_3  GR_entropy_foot10  ILD_log10_entropy_foot10  \\\n",
       "count         4151.000000        4151.000000               4151.000000   \n",
       "mean        -22018.571435           0.803226                  0.779793   \n",
       "std          41441.902455           0.728947                  0.740483   \n",
       "min         -99999.000000           0.000000                  0.000000   \n",
       "25%             -0.231496           0.000000                  0.000000   \n",
       "50%             -0.027656           0.918296                  0.918296   \n",
       "75%              0.025482           1.584963                  1.584963   \n",
       "max              1.523253           1.584963                  1.584963   \n",
       "\n",
       "       DeltaPHI_entropy_foot10  PHIND_entropy_foot10  PE_entropy_foot10  \n",
       "count              4151.000000           4151.000000        4151.000000  \n",
       "mean                  0.870575              0.832670           0.545273  \n",
       "std                   0.720045              0.738475           0.685700  \n",
       "min                   0.000000              0.000000           0.000000  \n",
       "25%                   0.000000              0.000000           0.000000  \n",
       "50%                   0.918296              0.918296           0.000000  \n",
       "75%                   1.584963              1.584963           1.584963  \n",
       "max                   1.584963              1.584963           1.584963  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_pickle('../../2016-ml-contest_liamlearn/data/training_data.pkl')\n",
    "training_data.drop_duplicates(inplace=True)\n",
    "# training_data = training_data[training_data['Well Name'] != 'Recruit F9']\n",
    "training_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is LUKE G U, F1 score : 64.5898%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is NEWBY, F1 score : 48.1006%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is KIMZEY A, F1 score : 48.4954%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is NOLAN, F1 score : 51.4632%\n",
      "\n",
      "********\n",
      "Blind well is CROSS H CATTLE, F1 score : 33.7938%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is CHURCHMAN BIBLE, F1 score : 40.5155%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is ALEXANDER D, F1 score : 58.0558%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is SHRIMPLIN, F1 score : 54.9580%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is Recruit F9, F1 score : 60.8696%\n",
      "\n",
      "********\n",
      "Blind well is SHANKLE, F1 score : 46.8888%\n",
      "\n",
      "==============================\n",
      "*********** RESULT ***********\n",
      "==============================\n",
      "\n",
      "Average  F1-score is 50.7730%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "#Create a set of unique well names\n",
    "\n",
    "names = list(set(training_data[\"Well Name\"]))\n",
    "\n",
    "#Create a dicitionary of the well datasets, continued from original contest notebook \n",
    "#But perform dropping for each well individually\n",
    "#Maybe not necessary.\n",
    "\n",
    "well_datas = {}\n",
    "for name in names:\n",
    "    well = training_data[training_data[\"Well Name\"]==name] \n",
    "    well_labels = well['Facies'].values.astype(np.int64)\n",
    "    well = well.drop(['Formation', 'Well Name', 'Depth','Facies','FaciesLabels'], axis=1).values\n",
    "    well_datas[name] = [well, well_labels]\n",
    "    \n",
    "    \n",
    "X_data = {}\n",
    "y_data = {}\n",
    "for name, (data, labels) in well_datas.items():\n",
    "    y_data[name] = np.array(labels, dtype=np.int64)\n",
    "    X_data[name] = np.array(data, dtype=np.float32)\n",
    "\n",
    "training_sets = []\n",
    "test_sets = []\n",
    "\n",
    "for i in range(len(names)):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for name, data in X_data.items():\n",
    "        if name is not names[i]:\n",
    "            for row in data:\n",
    "                X_train.append(row)\n",
    "        else:\n",
    "            for row in data:\n",
    "                X_test.append(row)\n",
    "\n",
    "    for name, labels in y_data.items():\n",
    "        if name is not names[i]:\n",
    "            for val in labels:\n",
    "                y_train.append(val)\n",
    "        else:\n",
    "            for val in labels:\n",
    "                y_test.append(val)\n",
    "\n",
    "    X_train = np.array(X_train, dtype=np.float32)\n",
    "    y_train = np.array(y_train, dtype=np.int64).reshape(len(y_train), 1)\n",
    "    y_train = y_train.ravel()\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "    X_test = np.array(X_test, dtype=np.float32)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    y_test = np.array(y_test, dtype=np.int32)\n",
    "    training_sets.append([X_train, y_train, X_test, y_test])\n",
    "    \n",
    "#Use as follows:\n",
    "scores = []\n",
    "for i, (X_train, y_train, X_test, y_test) in enumerate(training_sets):\n",
    "#     clf = svm.LinearSVC(class_weight='balanced', tol=1e-03, random_state=42, C=10)\n",
    "    clf = ensemble.RandomForestClassifier(n_estimators=300, class_weight='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #Scoring\n",
    "    score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    scores.append(score)\n",
    "    print('********')\n",
    "    print('Blind well is {0}, F1 score : {1:.4%}\\n'.format(names[i],score))\n",
    "#     print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    pass\n",
    "print(\"=\"*30)\n",
    "print('*********** RESULT ***********')\n",
    "print(\"=\"*30)\n",
    "print('\\nAverage  F1-score is {:.4%}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold cross validation shows that the F1-score for each well is highly variable. For example, the model fit well for SHANKLE but less SHRIMPLIN. This is way, as @LukasMosser and me suggest is to use the average F1-score as a metricsto evaluate the performance of the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "CPython 3.5.2\n",
      "IPython 5.1.0\n",
      "\n",
      "numpy 1.11.1\n",
      "scipy 0.18.0\n",
      "pandas 0.18.1\n",
      "matplotlib 1.5.1\n",
      "seaborn 0.7.1\n",
      "sklearn 0.19.dev0\n",
      "pywt 0.4.0\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)\n",
      "system     : Darwin\n",
      "release    : 16.1.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,seaborn,sklearn,pywt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# import seaborn as sns\n",
    "\n",
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 30)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_logs = pd.read_pickle('data/training_data_raw.pkl')\n",
    "raw_logs.replace(to_replace=np.nan, value=-99999.0, inplace=True)\n",
    "\n",
    "dwt = pd.read_pickle('data/vars_from_dwt.pkl')\n",
    "dwt.replace(to_replace=np.nan, value=-99999.0, inplace=True)\n",
    "\n",
    "entropy = pd.read_pickle('data/vars_from_log_entropy.pkl')\n",
    "entropy.replace(to_replace=np.nan, value=-99999.0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>...</th>\n",
       "      <th>PE_cD_step_level_2</th>\n",
       "      <th>PE_cD_step_level_3</th>\n",
       "      <th>PE_cD_step_level_4</th>\n",
       "      <th>PE_cD_step_level_5</th>\n",
       "      <th>PE_cD_step_level_6</th>\n",
       "      <th>GR_entropy_foot5</th>\n",
       "      <th>ILD_log10_entropy_foot5</th>\n",
       "      <th>DeltaPHI_entropy_foot5</th>\n",
       "      <th>PHIND_entropy_foot5</th>\n",
       "      <th>PE_entropy_foot5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>77.45</td>\n",
       "      <td>0.664</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.915</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109651</td>\n",
       "      <td>0.109651</td>\n",
       "      <td>0.109651</td>\n",
       "      <td>0.109651</td>\n",
       "      <td>0.109651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>78.26</td>\n",
       "      <td>0.661</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.565</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>0.658</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.050</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.5</td>\n",
       "      <td>86.10</td>\n",
       "      <td>0.655</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.115</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>74.58</td>\n",
       "      <td>0.647</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.300</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facies Formation  Well Name   Depth     GR  ILD_log10  DeltaPHI   PHIND  \\\n",
       "0       3     A1 SH  SHRIMPLIN  2793.0  77.45      0.664       9.9  11.915   \n",
       "1       3     A1 SH  SHRIMPLIN  2793.5  78.26      0.661      14.2  12.565   \n",
       "2       3     A1 SH  SHRIMPLIN  2794.0  79.05      0.658      14.8  13.050   \n",
       "3       3     A1 SH  SHRIMPLIN  2794.5  86.10      0.655      13.9  13.115   \n",
       "4       3     A1 SH  SHRIMPLIN  2795.0  74.58      0.647      13.5  13.300   \n",
       "\n",
       "    PE  NM_M        ...         PE_cD_step_level_2  PE_cD_step_level_3  \\\n",
       "0  4.6     1        ...                   0.109651            0.109651   \n",
       "1  4.1     1        ...                  -0.228628           -0.228628   \n",
       "2  3.6     1        ...                  -0.228628           -0.228628   \n",
       "3  3.5     1        ...                  -0.037444           -0.037444   \n",
       "4  3.4     1        ...                  -0.037444           -0.037444   \n",
       "\n",
       "   PE_cD_step_level_4  PE_cD_step_level_5  PE_cD_step_level_6  \\\n",
       "0            0.109651            0.109651            0.109651   \n",
       "1           -0.228628           -0.228628           -0.228628   \n",
       "2           -0.228628           -0.228628           -0.228628   \n",
       "3           -0.037444           -0.037444           -0.037444   \n",
       "4           -0.037444           -0.037444           -0.037444   \n",
       "\n",
       "   GR_entropy_foot5  ILD_log10_entropy_foot5  DeltaPHI_entropy_foot5  \\\n",
       "0          1.000000                 1.000000                1.000000   \n",
       "1          0.918296                 1.584963                1.584963   \n",
       "2          0.918296                 1.584963                1.584963   \n",
       "3          1.584963                 1.584963                1.584963   \n",
       "4          0.918296                 1.584963                1.584963   \n",
       "\n",
       "   PHIND_entropy_foot5  PE_entropy_foot5  \n",
       "0             1.000000          1.000000  \n",
       "1             1.584963          1.584963  \n",
       "2             1.584963          0.918296  \n",
       "3             1.584963          0.000000  \n",
       "4             1.584963          0.000000  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.merge(raw_logs,dwt,on=['Depth','Well Name'])\n",
    "training_data = pd.merge(training_data,entropy, on=['Depth','Well Name'])\n",
    "\n",
    "# training_data = raw_logs\n",
    "training_data.head()\n",
    "# training_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PE_mask = training_data['PE'].notnull().values\n",
    "training_data = training_data[PE_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSiS    946\n",
       "FSiS    786\n",
       "PS      692\n",
       "WS      582\n",
       "MS      296\n",
       "SiSh    271\n",
       "SS      268\n",
       "BS      185\n",
       "D       141\n",
       "Name: FaciesLabels, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1=sandstone  2=c_siltstone   3=f_siltstone \n",
    "# 4=marine_silt_shale 5=mudstone 6=wackestone 7=dolomite\n",
    "# 8=packstone 9=bafflestone\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',\n",
    "       '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS',\n",
    "                 'WS', 'D','PS', 'BS']\n",
    "#facies_color_map is a dictionary that maps facies labels\n",
    "#to their respective colors\n",
    "facies_color_map = {}\n",
    "for ind, label in enumerate(facies_labels):\n",
    "    facies_color_map[label] = facies_colors[ind]\n",
    "\n",
    "def label_facies(row, labels):\n",
    "    return labels[ row['Facies'] -1]\n",
    "    \n",
    "training_data.loc[:,'FaciesLabels'] = training_data.apply(lambda row: label_facies(row, facies_labels), axis=1)\n",
    "training_data.replace(to_replace=np.nan, value=-99999.0, inplace=True)\n",
    "training_data['FaciesLabels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set\n",
    "Remove a single well to use as a blind test later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SHRIMPLIN', 'ALEXANDER D', 'LUKE G U', 'KIMZEY A',\n",
       "       'CROSS H CATTLE', 'NOLAN', 'Recruit F9', 'NEWBY', 'CHURCHMAN BIBLE'], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blind = training_data[training_data['Well Name'] == 'SHANKLE']\n",
    "training_data = training_data[training_data['Well Name'] != 'SHANKLE']\n",
    "training_data['Well Name'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test set\n",
    "\n",
    "Now we extract just the feature variables we need to perform the classification.  The predictor variables are the five wireline values and two geologic constraining variables. We also get a vector of the facies labels that correspond to each feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3718, 43)\n",
      "(449, 43)\n",
      "(3718,)\n",
      "(449,)\n"
     ]
    }
   ],
   "source": [
    "X_train = training_data.drop(['Formation', 'Well Name','Facies','FaciesLabels'], axis=1).values\n",
    "y_train = training_data['Facies'].values\n",
    "X_test = blind.drop(['Formation', 'Well Name','Facies','FaciesLabels'], axis=1).values\n",
    "y_test = blind['Facies'].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# feature_vectors = training_data.drop(['Formation', 'Well Name', 'Depth','Facies','FaciesLabels'], axis=1)\n",
    "# feature_vectors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.: [  0 161 771 602 237 249 459 111 586 166], Acc: 0.556\n",
      "Fold: 2, Class dist.: [  0 161 771 602 237 249 460 111 586 166], Acc: 0.589\n",
      "Fold: 3, Class dist.: [  0 161 771 602 237 249 460 111 587 166], Acc: 0.580\n",
      "Fold: 4, Class dist.: [  0 161 771 602 237 249 460 111 587 166], Acc: 0.521\n",
      "Fold: 5, Class dist.: [  0 161 771 602 238 249 460 112 587 166], Acc: 0.433\n",
      "Fold: 6, Class dist.: [  0 161 771 602 238 249 460 112 587 167], Acc: 0.345\n",
      "Fold: 7, Class dist.: [  0 161 771 602 238 249 460 112 587 167], Acc: 0.383\n",
      "Fold: 8, Class dist.: [  0 161 772 602 238 250 460 112 587 167], Acc: 0.585\n",
      "Fold: 9, Class dist.: [  0 161 772 602 238 250 460 112 587 167], Acc: 0.612\n",
      "Fold: 10, Class dist.: [  0 162 772 603 238 250 460 112 587 167], Acc: 0.466\n",
      "\n",
      "CV accuracy: 0.507 +/- 0.090\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# scores = cross_val_score(estimator=clf,\n",
    "#                          X=X_train,\n",
    "#                          y=y_train,\n",
    "#                          cv=10,\n",
    "#                          n_jobs=1,\n",
    "#                          scoring='f1_micro')\n",
    "# print('CV f1 scores: %s' % scores)\n",
    "# print('CV f1: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "    \n",
    "kfold = StratifiedKFold(n_splits=10,\n",
    "                            random_state=1).split(X_train, y_train)\n",
    "\n",
    "# clf = ensemble.RandomForestClassifier(n_estimators=1000)\n",
    "# clf = svm.LinearSVC(class_weight='balanced', tol=1e-03) \n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    clf.fit(X_train[train], y_train[train])\n",
    "    score = clf.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "          np.bincount(y_train[train]), score))\n",
    "    \n",
    "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Results****\n",
      "\n",
      "Accuracy: 47.6615%\n",
      "Precision: 47.6615%\n",
      "Recall: 47.6615%\n",
      "F1 score: 47.6615%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         SS       0.00      0.00      0.00        89\n",
      "       CSiS       0.38      0.78      0.51        89\n",
      "       FSiS       0.77      0.73      0.75       117\n",
      "       SiSh       0.12      0.14      0.13         7\n",
      "         MS       0.29      0.63      0.39        19\n",
      "         WS       0.53      0.42      0.47        71\n",
      "          D       0.50      0.06      0.11        17\n",
      "         PS       0.37      0.40      0.39        40\n",
      "         BS       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.43      0.48      0.43       449\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('****Results****\\n')\n",
    "predicted_labels = clf.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "print(\"Accuracy: {:.4%}\".format(accuracy))\n",
    "precision = metrics.precision_score(y_test, predicted_labels, average='micro')\n",
    "print(\"Precision: {:.4%}\".format(precision))\n",
    "    \n",
    "recall = metrics.recall_score(y_test, predicted_labels, average='micro')\n",
    "print(\"Recall: {:.4%}\".format(recall))\n",
    "    \n",
    "f1 = metrics.f1_score(y_test, predicted_labels, average='micro')\n",
    "print(\"F1 score: {:.4%}\".format(f1))\n",
    "    \n",
    "print(metrics.classification_report(y_test, predicted_labels,target_names=facies_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SHANKLE    449\n",
       "Name: Well Name, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blind['Well Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from classification_utilities import display_cm, display_adj_cm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def accuracy(conf):\n",
    "    total_correct = 0.\n",
    "    nb_classes = conf.shape[0]\n",
    "    for i in np.arange(0,nb_classes):\n",
    "        total_correct += conf[i][i]\n",
    "    acc = total_correct/sum(sum(conf))\n",
    "    return acc\n",
    "\n",
    "adjacent_facies = np.array([[1], [0,2], [1], [4], [3,5], [4,6,7], [5,7], [5,6,8], [6,7]])\n",
    "\n",
    "def accuracy_adjacent(conf, adjacent_facies):\n",
    "    nb_classes = conf.shape[0]\n",
    "    total_correct = 0.\n",
    "    for i in np.arange(0,nb_classes):\n",
    "        total_correct += conf[i][i]\n",
    "        for j in adjacent_facies[i]:\n",
    "            total_correct += conf[i][j]\n",
    "    return total_correct / sum(sum(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    \n",
    "    ensemble.RandomForestClassifier(n_estimators=1000),\n",
    "    ensemble.GradientBoostingClassifier(min_samples_split=1),\n",
    "    ensemble.BaggingClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "LinearSVC\n",
      "****Results****\n",
      "\n",
      "Accuracy: 48.3801%\n",
      "Precision: 48.3801%\n",
      "Recall: 48.3801%\n",
      "F1 score: 48.3801%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.64      0.66      0.65        98\n",
      "          3       0.65      0.53      0.58        80\n",
      "          4       0.64      0.40      0.49        58\n",
      "          5       0.00      0.00      0.00        28\n",
      "          6       0.52      0.30      0.38        96\n",
      "          7       0.41      0.88      0.56        16\n",
      "          8       0.38      0.54      0.44        56\n",
      "          9       0.30      0.68      0.41        31\n",
      "\n",
      "avg / total       0.51      0.48      0.48       463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "\n",
      "Accuracy: 54.2117%\n",
      "Precision: 54.2117%\n",
      "Recall: 54.2117%\n",
      "F1 score: 54.2117%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.64      0.71      0.68        98\n",
      "          3       0.58      0.50      0.54        80\n",
      "          4       0.90      0.66      0.76        58\n",
      "          5       0.14      0.07      0.10        28\n",
      "          6       0.55      0.44      0.49        96\n",
      "          7       0.55      0.38      0.44        16\n",
      "          8       0.36      0.86      0.51        56\n",
      "          9       1.00      0.16      0.28        31\n",
      "\n",
      "avg / total       0.60      0.54      0.53       463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "\n",
      "Accuracy: 51.8359%\n",
      "Precision: 51.8359%\n",
      "Recall: 51.8359%\n",
      "F1 score: 51.8359%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.68      0.72      0.70        98\n",
      "          3       0.62      0.57      0.60        80\n",
      "          4       0.81      0.66      0.72        58\n",
      "          5       0.00      0.00      0.00        28\n",
      "          6       0.49      0.38      0.42        96\n",
      "          7       0.37      0.44      0.40        16\n",
      "          8       0.35      0.75      0.47        56\n",
      "          9       0.00      0.00      0.00        31\n",
      "\n",
      "avg / total       0.51      0.52      0.50       463\n",
      "\n",
      "==============================\n",
      "BaggingClassifier\n",
      "****Results****\n",
      "\n",
      "Accuracy: 46.8683%\n",
      "Precision: 46.8683%\n",
      "Recall: 46.8683%\n",
      "F1 score: 46.8683%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.60      0.60      0.60        98\n",
      "          3       0.59      0.49      0.53        80\n",
      "          4       0.81      0.66      0.72        58\n",
      "          5       0.03      0.04      0.03        28\n",
      "          6       0.52      0.33      0.41        96\n",
      "          7       0.50      0.38      0.43        16\n",
      "          8       0.33      0.68      0.44        56\n",
      "          9       0.40      0.13      0.20        31\n",
      "\n",
      "avg / total       0.52      0.47      0.48       463\n",
      "\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****\\n')\n",
    "    predicted_labels = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "    print(\"Accuracy: {:.4%}\".format(accuracy))\n",
    "#     conf = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "#     print('Optimized facies classification accuracy = %.2f' % accuracy(conf))\n",
    "#     print('Optimized adjacent facies classification accuracy = %.2f\\n' % accuracy_adjacent(conf, adjacent_facies))\n",
    "    \n",
    "#     display_adj_cm(conf, facies_labels, adjacent_facies,display_metrics=True, hide_zeros=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    precision = metrics.precision_score(y_test, predicted_labels, average='micro')\n",
    "    print(\"Precision: {:.4%}\".format(precision))\n",
    "    \n",
    "    recall = metrics.recall_score(y_test, predicted_labels, average='micro')\n",
    "    print(\"Recall: {:.4%}\".format(recall))\n",
    "    \n",
    "    f1 = metrics.f1_score(y_test, predicted_labels, average='micro')\n",
    "    print(\"F1 score: {:.4%}\".format(f1))\n",
    "    \n",
    "    print(metrics.classification_report(y_test, predicted_labels))\n",
    "       \n",
    "    log_entry = pd.DataFrame([[name, accuracy*100, precision*100, recall*100, f1*100]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

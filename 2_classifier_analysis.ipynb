{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 5.1.0\n",
      "\n",
      "numpy 1.11.1\n",
      "scipy 0.18.0\n",
      "pandas 0.18.1\n",
      "matplotlib 1.5.1\n",
      "seaborn 0.7.1\n",
      "sklearn 0.18\n",
      "pywt 0.4.0\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)\n",
      "system     : Darwin\n",
      "release    : 16.1.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,seaborn,sklearn,pywt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>GR_cD_step_level_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PE_cD_step_level_2</th>\n",
       "      <th>PE_cD_step_level_3</th>\n",
       "      <th>PE_cD_step_level_4</th>\n",
       "      <th>PE_cD_step_level_5</th>\n",
       "      <th>PE_cD_step_level_6</th>\n",
       "      <th>GR_entropy_foot5</th>\n",
       "      <th>ILD_log10_entropy_foot5</th>\n",
       "      <th>DeltaPHI_entropy_foot5</th>\n",
       "      <th>PHIND_entropy_foot5</th>\n",
       "      <th>PE_entropy_foot5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "      <td>4167.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.502520</td>\n",
       "      <td>2906.351092</td>\n",
       "      <td>65.248225</td>\n",
       "      <td>0.659125</td>\n",
       "      <td>4.412696</td>\n",
       "      <td>13.203811</td>\n",
       "      <td>-22003.113383</td>\n",
       "      <td>1.519078</td>\n",
       "      <td>0.523053</td>\n",
       "      <td>-0.198926</td>\n",
       "      <td>...</td>\n",
       "      <td>-21934.026972</td>\n",
       "      <td>-21934.026972</td>\n",
       "      <td>-21934.026972</td>\n",
       "      <td>-21934.026972</td>\n",
       "      <td>-21934.026972</td>\n",
       "      <td>0.803668</td>\n",
       "      <td>0.778121</td>\n",
       "      <td>0.869436</td>\n",
       "      <td>0.831015</td>\n",
       "      <td>0.546265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.475018</td>\n",
       "      <td>133.443259</td>\n",
       "      <td>30.951925</td>\n",
       "      <td>0.252315</td>\n",
       "      <td>5.267093</td>\n",
       "      <td>7.119856</td>\n",
       "      <td>41434.948570</td>\n",
       "      <td>0.499696</td>\n",
       "      <td>0.287208</td>\n",
       "      <td>5.096861</td>\n",
       "      <td>...</td>\n",
       "      <td>41384.660580</td>\n",
       "      <td>41384.660580</td>\n",
       "      <td>41384.660580</td>\n",
       "      <td>41384.660580</td>\n",
       "      <td>41384.660580</td>\n",
       "      <td>0.727580</td>\n",
       "      <td>0.740063</td>\n",
       "      <td>0.719423</td>\n",
       "      <td>0.738078</td>\n",
       "      <td>0.684827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2573.500000</td>\n",
       "      <td>10.149000</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-21.832000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-96.538551</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2820.750000</td>\n",
       "      <td>44.912000</td>\n",
       "      <td>0.497034</td>\n",
       "      <td>1.602000</td>\n",
       "      <td>8.512250</td>\n",
       "      <td>2.442500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>-1.206098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>-0.228628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2932.500000</td>\n",
       "      <td>65.125000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>12.036000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.015539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027043</td>\n",
       "      <td>-0.027043</td>\n",
       "      <td>-0.027043</td>\n",
       "      <td>-0.027043</td>\n",
       "      <td>-0.027043</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3006.500000</td>\n",
       "      <td>79.535000</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>16.057000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.140359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>361.150000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>19.312000</td>\n",
       "      <td>84.400000</td>\n",
       "      <td>8.094000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.034509</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Facies        Depth           GR    ILD_log10     DeltaPHI  \\\n",
       "count  4167.000000  4167.000000  4167.000000  4167.000000  4167.000000   \n",
       "mean      4.502520  2906.351092    65.248225     0.659125     4.412696   \n",
       "std       2.475018   133.443259    30.951925     0.252315     5.267093   \n",
       "min       1.000000  2573.500000    10.149000    -0.025949   -21.832000   \n",
       "25%       2.000000  2820.750000    44.912000     0.497034     1.602000   \n",
       "50%       4.000000  2932.500000    65.125000     0.639000     4.300000   \n",
       "75%       6.000000  3006.500000    79.535000     0.821000     7.500000   \n",
       "max       9.000000  3138.000000   361.150000     1.800000    19.312000   \n",
       "\n",
       "             PHIND            PE         NM_M       RELPOS  \\\n",
       "count  4167.000000   4167.000000  4167.000000  4167.000000   \n",
       "mean     13.203811 -22003.113383     1.519078     0.523053   \n",
       "std       7.119856  41434.948570     0.499696     0.287208   \n",
       "min       0.550000 -99999.000000     1.000000     0.000000   \n",
       "25%       8.512250      2.442500     1.000000     0.278000   \n",
       "50%      12.036000      3.300000     2.000000     0.528000   \n",
       "75%      16.057000      4.000000     2.000000     0.769000   \n",
       "max      84.400000      8.094000     2.000000     1.000000   \n",
       "\n",
       "       GR_cD_step_level_1        ...         PE_cD_step_level_2  \\\n",
       "count         4167.000000        ...                4167.000000   \n",
       "mean            -0.198926        ...              -21934.026972   \n",
       "std              5.096861        ...               41384.660580   \n",
       "min            -96.538551        ...              -99999.000000   \n",
       "25%             -1.206098        ...                  -0.228628   \n",
       "50%              0.015539        ...                  -0.027043   \n",
       "75%              1.140359        ...                   0.024787   \n",
       "max             41.034509        ...                   1.523253   \n",
       "\n",
       "       PE_cD_step_level_3  PE_cD_step_level_4  PE_cD_step_level_5  \\\n",
       "count         4167.000000         4167.000000         4167.000000   \n",
       "mean        -21934.026972       -21934.026972       -21934.026972   \n",
       "std          41384.660580        41384.660580        41384.660580   \n",
       "min         -99999.000000       -99999.000000       -99999.000000   \n",
       "25%             -0.228628           -0.228628           -0.228628   \n",
       "50%             -0.027043           -0.027043           -0.027043   \n",
       "75%              0.024787            0.024787            0.024787   \n",
       "max              1.523253            1.523253            1.523253   \n",
       "\n",
       "       PE_cD_step_level_6  GR_entropy_foot5  ILD_log10_entropy_foot5  \\\n",
       "count         4167.000000       4167.000000              4167.000000   \n",
       "mean        -21934.026972          0.803668                 0.778121   \n",
       "std          41384.660580          0.727580                 0.740063   \n",
       "min         -99999.000000          0.000000                 0.000000   \n",
       "25%             -0.228628          0.000000                 0.000000   \n",
       "50%             -0.027043          0.918296                 0.918296   \n",
       "75%              0.024787          1.584963                 1.584963   \n",
       "max              1.523253          1.584963                 1.584963   \n",
       "\n",
       "       DeltaPHI_entropy_foot5  PHIND_entropy_foot5  PE_entropy_foot5  \n",
       "count             4167.000000          4167.000000       4167.000000  \n",
       "mean                 0.869436             0.831015          0.546265  \n",
       "std                  0.719423             0.738078          0.684827  \n",
       "min                  0.000000             0.000000          0.000000  \n",
       "25%                  0.000000             0.000000          0.000000  \n",
       "50%                  0.918296             0.918296          0.000000  \n",
       "75%                  1.584963             1.584963          1.584963  \n",
       "max                  1.584963             1.584963          1.584963  \n",
       "\n",
       "[8 rows x 44 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "# import seaborn as sns\n",
    "\n",
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 50)\n",
    "pd.options.mode.chained_assignment = None\n",
    "filename = 'data/training_data.pkl'\n",
    "training_data = pd.read_pickle(filename)\n",
    "training_data.describe()\n",
    "# training_data.isnull().sum()\n",
    "# training_data['Well Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSiS    946\n",
       "FSiS    786\n",
       "PS      692\n",
       "WS      582\n",
       "MS      296\n",
       "SiSh    271\n",
       "SS      268\n",
       "BS      185\n",
       "D       141\n",
       "Name: FaciesLabels, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1=sandstone  2=c_siltstone   3=f_siltstone \n",
    "# 4=marine_silt_shale 5=mudstone 6=wackestone 7=dolomite\n",
    "# 8=packstone 9=bafflestone\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',\n",
    "       '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS',\n",
    "                 'WS', 'D','PS', 'BS']\n",
    "#facies_color_map is a dictionary that maps facies labels\n",
    "#to their respective colors\n",
    "facies_color_map = {}\n",
    "for ind, label in enumerate(facies_labels):\n",
    "    facies_color_map[label] = facies_colors[ind]\n",
    "\n",
    "def label_facies(row, labels):\n",
    "    return labels[ row['Facies'] -1]\n",
    "    \n",
    "training_data.loc[:,'FaciesLabels'] = training_data.apply(lambda row: label_facies(row, facies_labels), axis=1)\n",
    "training_data.replace(to_replace=np.nan, value=-99999.0, inplace=True)\n",
    "training_data['FaciesLabels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1152f02b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQW9mVjgHvZlZ4f4/RM1BM3Pvu7YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150cda20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count the number of unique entries for each facies, sort them by\n",
    "#facies number (instead of by number of entries)\n",
    "facies_counts = training_data['Facies'].value_counts().sort_index()\n",
    "#use facies labels to index each count\n",
    "facies_counts.index = facies_labels\n",
    "sns.reset_orig()\n",
    "facies_counts.plot(kind='bar',color=facies_colors, \n",
    "                   title='Distribution of Training Data by Facies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set\n",
    "Remove a single well to use as a blind test later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SHRIMPLIN', 'ALEXANDER D', 'SHANKLE', 'LUKE G U', 'KIMZEY A',\n",
       "       'CROSS H CATTLE', 'NOLAN', 'Recruit F9', 'NEWBY'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blind = training_data[training_data['Well Name'] == 'SHANKLE']\n",
    "training_data = training_data[training_data['Well Name'] != 'SHANKLE']\n",
    "training_data['Well Name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = training_data['Facies'].values\n",
    "\n",
    "X = training_data.drop(['Formation', 'Well Name', 'Depth','Facies','FaciesLabels'], axis=1).values\n",
    "# X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2634, 42) (1129, 42) (2634,) (1129,)\n",
      "Fold: 1, Class dist.: [  0 163 560 462 162 167 311  67 388  85], f1-score: 0.683\n",
      "Fold: 2, Class dist.: [  0 163 560 462 163 167 311  67 388  85], f1-score: 0.651\n",
      "Fold: 3, Class dist.: [  0 164 560 462 163 167 311  67 389  85], f1-score: 0.709\n",
      "Fold: 4, Class dist.: [  0 164 561 462 163 167 311  67 389  85], f1-score: 0.741\n",
      "Fold: 5, Class dist.: [  0 164 561 463 163 167 311  67 389  85], f1-score: 0.720\n",
      "Fold: 6, Class dist.: [  0 164 561 463 163 167 311  68 389  86], f1-score: 0.673\n",
      "Fold: 7, Class dist.: [  0 164 561 463 163 168 312  68 389  86], f1-score: 0.711\n",
      "Fold: 8, Class dist.: [  0 164 561 463 163 168 312  68 389  86], f1-score: 0.733\n",
      "Fold: 9, Class dist.: [  0 164 561 463 163 168 312  68 389  86], f1-score: 0.727\n",
      "Fold: 10, Class dist.: [  0 164 561 463 163 168 312  68 389  86], f1-score: 0.729\n",
      "\n",
      "CV accuracy: 0.708 +/- 0.028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "pipe_rf = make_pipeline(StandardScaler(), \n",
    "                        ensemble.RandomForestClassifier())\n",
    "\n",
    "kfold = StratifiedKFold(y=y_train, \n",
    "                        n_folds=10,\n",
    "                        random_state=1)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "#     print(train.shape, test.shape)\n",
    "    pipe_rf.fit(X_train[train], y_train[train])\n",
    "    score = metrics.f1_score(y_train[test], pipe_rf.predict(X_train[test]), average='weighted')\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, f1-score: %.3f' % (k+1,\n",
    "          np.bincount(y_train[train]), score))\n",
    "    \n",
    "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7572888263393361\n",
      "{'randomforestclassifier__n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'randomforestclassifier__n_estimators': [10, 100, 1000],\n",
    "              'randomforestclassifier__criterion'}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_rf, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='f1_weighted', \n",
    "                  cv=10,\n",
    "                  n_jobs=1,\n",
    "                  refit=True)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test set\n",
    "\n",
    "Now we extract just the feature variables we need to perform the classification.  The predictor variables are the five wireline values and two geologic constraining variables. We also get a vector of the facies labels that correspond to each feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3763, 43)\n",
      "(404, 43)\n",
      "(3763,)\n",
      "(404,)\n"
     ]
    }
   ],
   "source": [
    "X_train = training_data.drop(['Formation', 'Well Name','Facies','FaciesLabels'], axis=1).values\n",
    "y_train = training_data['Facies'].values\n",
    "X_test = blind.drop(['Formation', 'Well Name','Facies','FaciesLabels'], axis=1).values\n",
    "y_test = blind['Facies'].values\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# X_scaler = StandardScaler()\n",
    "# X_train = X_scaler.fit_transform(X_train)\n",
    "# X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# feature_vectors = training_data.drop(['Formation', 'Well Name', 'Depth','Facies','FaciesLabels'], axis=1)\n",
    "# feature_vectors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Results****\n",
      "\n",
      "F1 score: 45.1621%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=1000, criterion=\"mae\")\n",
    "clf.fit(X_train, y_train)\n",
    "print('****Results****\\n')\n",
    "predicted_labels = clf.predict(X_test)\n",
    "f1 = metrics.f1_score(y_test, predicted_labels, average='weighted')\n",
    "print(\"F1 score: {:.4%}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>GR_cD_step_level_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PHIND_cD_step_level_3</th>\n",
       "      <th>PE_cD_step_level_1</th>\n",
       "      <th>PE_cD_step_level_2</th>\n",
       "      <th>PE_cD_step_level_3</th>\n",
       "      <th>GR_entropy_foot10</th>\n",
       "      <th>ILD_log10_entropy_foot10</th>\n",
       "      <th>DeltaPHI_entropy_foot10</th>\n",
       "      <th>PHIND_entropy_foot10</th>\n",
       "      <th>PE_entropy_foot10</th>\n",
       "      <th>PHINDxPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "      <td>4.151000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.502048</td>\n",
       "      <td>2906.778126</td>\n",
       "      <td>64.938671</td>\n",
       "      <td>0.659477</td>\n",
       "      <td>4.404699</td>\n",
       "      <td>13.203233</td>\n",
       "      <td>-22087.939466</td>\n",
       "      <td>1.518429</td>\n",
       "      <td>0.522082</td>\n",
       "      <td>-0.149963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022784</td>\n",
       "      <td>-22018.571435</td>\n",
       "      <td>-22018.571435</td>\n",
       "      <td>-22018.571435</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.779793</td>\n",
       "      <td>0.870575</td>\n",
       "      <td>0.832670</td>\n",
       "      <td>0.545273</td>\n",
       "      <td>-2.696186e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.474337</td>\n",
       "      <td>133.330124</td>\n",
       "      <td>30.295980</td>\n",
       "      <td>0.252675</td>\n",
       "      <td>5.274641</td>\n",
       "      <td>7.131810</td>\n",
       "      <td>41492.164833</td>\n",
       "      <td>0.499720</td>\n",
       "      <td>0.286767</td>\n",
       "      <td>4.924412</td>\n",
       "      <td>...</td>\n",
       "      <td>1.268329</td>\n",
       "      <td>41441.902455</td>\n",
       "      <td>41441.902455</td>\n",
       "      <td>41441.902455</td>\n",
       "      <td>0.728947</td>\n",
       "      <td>0.740483</td>\n",
       "      <td>0.720045</td>\n",
       "      <td>0.738475</td>\n",
       "      <td>0.685700</td>\n",
       "      <td>5.484185e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2573.500000</td>\n",
       "      <td>10.149000</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-21.832000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-96.538551</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.212082</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>-99999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.010970e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2821.500000</td>\n",
       "      <td>44.740000</td>\n",
       "      <td>0.497034</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2.423000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>-1.202735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272629</td>\n",
       "      <td>-0.231496</td>\n",
       "      <td>-0.231496</td>\n",
       "      <td>-0.231496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.988060e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2932.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>12.030000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.027656</td>\n",
       "      <td>-0.027656</td>\n",
       "      <td>-0.027656</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.731000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3007.000000</td>\n",
       "      <td>79.438000</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>16.057000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.162370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280288</td>\n",
       "      <td>0.025482</td>\n",
       "      <td>0.025482</td>\n",
       "      <td>0.025482</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>5.148430e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3138.000000</td>\n",
       "      <td>361.150000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>19.312000</td>\n",
       "      <td>84.400000</td>\n",
       "      <td>8.094000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.034509</td>\n",
       "      <td>...</td>\n",
       "      <td>22.766611</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.523253</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.393473e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Facies        Depth           GR    ILD_log10     DeltaPHI  \\\n",
       "count  4151.000000  4151.000000  4151.000000  4151.000000  4151.000000   \n",
       "mean      4.502048  2906.778126    64.938671     0.659477     4.404699   \n",
       "std       2.474337   133.330124    30.295980     0.252675     5.274641   \n",
       "min       1.000000  2573.500000    10.149000    -0.025949   -21.832000   \n",
       "25%       2.000000  2821.500000    44.740000     0.497034     1.600000   \n",
       "50%       4.000000  2932.500000    65.000000     0.639000     4.300000   \n",
       "75%       6.000000  3007.000000    79.438000     0.822000     7.500000   \n",
       "max       9.000000  3138.000000   361.150000     1.800000    19.312000   \n",
       "\n",
       "             PHIND            PE         NM_M       RELPOS  \\\n",
       "count  4151.000000   4151.000000  4151.000000  4151.000000   \n",
       "mean     13.203233 -22087.939466     1.518429     0.522082   \n",
       "std       7.131810  41492.164833     0.499720     0.286767   \n",
       "min       0.550000 -99999.000000     1.000000     0.000000   \n",
       "25%       8.500000      2.423000     1.000000     0.277000   \n",
       "50%      12.030000      3.300000     2.000000     0.528000   \n",
       "75%      16.057000      4.000000     2.000000     0.769000   \n",
       "max      84.400000      8.094000     2.000000     1.000000   \n",
       "\n",
       "       GR_cD_step_level_1      ...       PHIND_cD_step_level_3  \\\n",
       "count         4151.000000      ...                 4151.000000   \n",
       "mean            -0.149963      ...                   -0.022784   \n",
       "std              4.924412      ...                    1.268329   \n",
       "min            -96.538551      ...                  -14.212082   \n",
       "25%             -1.202735      ...                   -0.272629   \n",
       "50%              0.013825      ...                   -0.001953   \n",
       "75%              1.162370      ...                    0.280288   \n",
       "max             41.034509      ...                   22.766611   \n",
       "\n",
       "       PE_cD_step_level_1  PE_cD_step_level_2  PE_cD_step_level_3  \\\n",
       "count         4151.000000         4151.000000         4151.000000   \n",
       "mean        -22018.571435       -22018.571435       -22018.571435   \n",
       "std          41441.902455        41441.902455        41441.902455   \n",
       "min         -99999.000000       -99999.000000       -99999.000000   \n",
       "25%             -0.231496           -0.231496           -0.231496   \n",
       "50%             -0.027656           -0.027656           -0.027656   \n",
       "75%              0.025482            0.025482            0.025482   \n",
       "max              1.523253            1.523253            1.523253   \n",
       "\n",
       "       GR_entropy_foot10  ILD_log10_entropy_foot10  DeltaPHI_entropy_foot10  \\\n",
       "count        4151.000000               4151.000000              4151.000000   \n",
       "mean            0.803226                  0.779793                 0.870575   \n",
       "std             0.728947                  0.740483                 0.720045   \n",
       "min             0.000000                  0.000000                 0.000000   \n",
       "25%             0.000000                  0.000000                 0.000000   \n",
       "50%             0.918296                  0.918296                 0.918296   \n",
       "75%             1.584963                  1.584963                 1.584963   \n",
       "max             1.584963                  1.584963                 1.584963   \n",
       "\n",
       "       PHIND_entropy_foot10  PE_entropy_foot10      PHINDxPE  \n",
       "count           4151.000000        4151.000000  4.151000e+03  \n",
       "mean               0.832670           0.545273 -2.696186e+05  \n",
       "std                0.738475           0.685700  5.484185e+05  \n",
       "min                0.000000           0.000000 -3.010970e+06  \n",
       "25%                0.000000           0.000000  1.988060e+01  \n",
       "50%                0.918296           0.000000  3.731000e+01  \n",
       "75%                1.584963           1.584963  5.148430e+01  \n",
       "max                1.584963           1.584963  1.393473e+02  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_pickle('data/training_data.pkl')\n",
    "training_data.drop_duplicates(inplace=True)\n",
    "# training_data = pd.read_pickle('data/training_data_raw.pkl')\n",
    "# training_data = pd.read_pickle('data/training_data_CannedGeo.pkl')\n",
    "\n",
    "# PE_mask = training_data['PE'].notnull().values\n",
    "# training_data = training_data[PE_mask]\n",
    "training_data['PHINDxPE'] = training_data['PHIND']*training_data['PE']\n",
    "training_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is KIMZEY A  , F1 score : 46.9443%\n",
      "(3712, 28) (3712,) (439, 28) (439,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         9\n",
      "          2       0.65      0.87      0.75        85\n",
      "          3       0.71      0.54      0.62        74\n",
      "          4       0.62      0.67      0.64        43\n",
      "          5       0.00      0.00      0.00        53\n",
      "          6       0.21      0.33      0.26        51\n",
      "          7       1.00      0.04      0.07        27\n",
      "          8       0.50      0.77      0.60        90\n",
      "          9       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.50      0.52      0.47       439\n",
      "\n",
      "[[ 0  5  4  0  0  0  0  0  0]\n",
      " [ 0 74 11  0  0  0  0  0  0]\n",
      " [ 0 34 40  0  0  0  0  0  0]\n",
      " [ 0  0  0 29  1 11  0  2  0]\n",
      " [ 0  0  0  3  0 32  0 18  0]\n",
      " [ 0  0  1  5  1 17  0 27  0]\n",
      " [ 0  0  0  8  0  2  1 16  0]\n",
      " [ 0  0  0  2  0 19  0 69  0]\n",
      " [ 0  0  0  0  0  0  0  7  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is LUKE G U  , F1 score : 67.2495%\n",
      "(3690, 28) (3690,) (461, 28) (461,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.63      0.74      0.68       117\n",
      "          3       0.82      0.55      0.66       129\n",
      "          4       0.78      0.83      0.81        35\n",
      "          5       0.00      0.00      0.00         2\n",
      "          6       0.72      0.67      0.69        84\n",
      "          7       0.89      0.40      0.55        20\n",
      "          8       0.61      0.69      0.65        74\n",
      "          9       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.72      0.66      0.67       461\n",
      "\n",
      "[[ 0  0  0  0  0  0  0  0  0]\n",
      " [16 87 14  0  0  0  0  0  0]\n",
      " [ 1 50 71  0  0  0  0  7  0]\n",
      " [ 0  0  1 29  1  4  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  1  0]\n",
      " [ 0  1  0  5  9 56  0 13  0]\n",
      " [ 0  0  0  0  0  0  8 11  1]\n",
      " [ 0  0  1  3  1 17  1 51  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is NOLAN     , F1 score : 50.8782%\n",
      "(3736, 28) (3736,) (415, 28) (415,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         4\n",
      "          2       0.74      0.66      0.70       118\n",
      "          3       0.58      0.63      0.61        68\n",
      "          4       0.67      0.14      0.24        28\n",
      "          5       0.00      0.00      0.00        47\n",
      "          6       0.16      0.40      0.23        30\n",
      "          7       0.25      0.50      0.33         4\n",
      "          8       0.68      0.58      0.63       116\n",
      "          9       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.56      0.50      0.51       415\n",
      "\n",
      "[[ 0  4  0  0  0  0  0  0  0]\n",
      " [11 78 28  0  0  0  0  1  0]\n",
      " [ 4 18 43  0  0  2  0  1  0]\n",
      " [ 1  0  0  4  3 17  1  2  0]\n",
      " [ 0  3  0  0  0 28  2 11  3]\n",
      " [ 1  0  0  0  0 12  1 15  1]\n",
      " [ 0  0  0  1  0  0  2  1  0]\n",
      " [ 0  2  3  1  0 16  2 67 25]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is SHANKLE   , F1 score : 47.1557%\n",
      "(3702, 28) (3702,) (449, 28) (449,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.04      0.08        89\n",
      "          2       0.34      0.72      0.46        89\n",
      "          3       0.79      0.61      0.69       117\n",
      "          4       0.07      0.14      0.09         7\n",
      "          5       0.00      0.00      0.00        19\n",
      "          6       0.69      0.69      0.69        71\n",
      "          7       0.82      0.53      0.64        17\n",
      "          8       0.51      0.68      0.58        40\n",
      "          9       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.51      0.50      0.47       449\n",
      "\n",
      "[[ 4 80  5  0  0  0  0  0  0]\n",
      " [11 64 14  0  0  0  0  0  0]\n",
      " [ 0 46 71  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  5  0  1  0]\n",
      " [ 0  0  0 11  0  5  1  2  0]\n",
      " [ 0  0  0  3  3 49  0 16  0]\n",
      " [ 0  0  0  0  0  1  9  7  0]\n",
      " [ 0  0  0  0  0 11  1 27  1]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is ALEXANDER D, F1 score : 59.1507%\n",
      "(3685, 28) (3685,) (466, 28) (466,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.86      0.72      0.78       117\n",
      "          3       0.70      0.85      0.77        91\n",
      "          4       0.61      0.84      0.70        44\n",
      "          5       0.29      0.31      0.30        26\n",
      "          6       0.42      0.22      0.29        69\n",
      "          7       0.20      0.50      0.28        16\n",
      "          8       0.54      0.51      0.53        98\n",
      "          9       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.61      0.60      0.59       466\n",
      "\n",
      "[[84 33  0  0  0  0  0  0]\n",
      " [14 77  0  0  0  0  0  0]\n",
      " [ 0  0 37  2  2  2  1  0]\n",
      " [ 0  0  2  8  5  1 10  0]\n",
      " [ 0  0 12 13 15  5 24  0]\n",
      " [ 0  0  0  0  1  8  7  0]\n",
      " [ 0  0  7  5 13 23 50  0]\n",
      " [ 0  0  3  0  0  2  0  0]]\n",
      "********\n",
      "Blind well is CROSS H CATTLE, F1 score : 33.8103%\n",
      "(3648, 28) (3648,) (503, 28) (503,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.16      0.27       158\n",
      "          2       0.33      0.45      0.38       144\n",
      "          3       0.27      0.79      0.40        47\n",
      "          4       0.29      0.08      0.12        25\n",
      "          5       0.50      0.04      0.07        28\n",
      "          6       0.27      0.71      0.39        31\n",
      "          7       0.00      0.00      0.00         2\n",
      "          8       0.63      0.46      0.53        68\n",
      "\n",
      "avg / total       0.58      0.36      0.34       503\n",
      "\n",
      "[[ 25 120  13   0   0   0   0   0]\n",
      " [  0  65  77   0   0   0   0   2]\n",
      " [  0   6  37   1   0   0   0   3]\n",
      " [  0   1   3   2   0  18   0   1]\n",
      " [  0   4   3   0   1  17   0   3]\n",
      " [  0   0   0   2   0  22   0   7]\n",
      " [  0   0   0   0   0   0   0   2]\n",
      " [  0   1   4   2   1  25   4  31]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is NEWBY     , F1 score : 52.2772%\n",
      "(3688, 28) (3688,) (463, 28) (463,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.63      0.67      0.65        98\n",
      "          3       0.58      0.50      0.54        80\n",
      "          4       0.90      0.66      0.76        58\n",
      "          5       0.07      0.04      0.05        28\n",
      "          6       0.52      0.45      0.48        96\n",
      "          7       0.55      0.38      0.44        16\n",
      "          8       0.36      0.82      0.50        56\n",
      "          9       1.00      0.16      0.28        31\n",
      "\n",
      "avg / total       0.59      0.53      0.52       463\n",
      "\n",
      "[[ 0  0  0  0  0  0  0  0  0]\n",
      " [ 5 66 27  0  0  0  0  0  0]\n",
      " [ 1 39 40  0  0  0  0  0  0]\n",
      " [ 0  0  0 38  0 19  0  1  0]\n",
      " [ 0  0  2  3  1  7  4 11  0]\n",
      " [ 0  0  0  1 11 43  0 41  0]\n",
      " [ 0  0  0  0  0  2  6  8  0]\n",
      " [ 0  0  0  0  2  7  1 46  0]\n",
      " [ 0  0  0  0  0  4  0 22  5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is Recruit F9, F1 score : 63.2479%\n",
      "(4071, 28) (4071,) (80, 28) (80,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          4       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00         0\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       1.00      0.46      0.63        80\n",
      "\n",
      "avg / total       1.00      0.46      0.63        80\n",
      "\n",
      "[[ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 3 11  2 27 37]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Blind well is SHRIMPLIN , F1 score : 55.6179%\n",
      "(3680, 28) (3680,) (471, 28) (471,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.68      0.75      0.72       118\n",
      "          3       0.81      0.65      0.72       123\n",
      "          4       0.61      0.61      0.61        18\n",
      "          5       0.00      0.00      0.00        63\n",
      "          6       0.39      0.60      0.47        63\n",
      "          7       0.00      0.00      0.00         5\n",
      "          8       0.53      0.83      0.65        69\n",
      "          9       0.50      0.17      0.25        12\n",
      "\n",
      "avg / total       0.55      0.59      0.56       471\n",
      "\n",
      "[[ 0  0  0  0  0  0  0  0  0]\n",
      " [10 89 19  0  0  0  0  0  0]\n",
      " [ 2 41 80  0  0  0  0  0  0]\n",
      " [ 0  0  0 11  0  3  0  4  0]\n",
      " [ 0  0  0  5  0 45  0 13  0]\n",
      " [ 0  0  0  2  0 38  2 20  1]\n",
      " [ 0  0  0  0  0  0  0  5  0]\n",
      " [ 0  0  0  0  1  9  1 57  1]\n",
      " [ 0  0  0  0  0  2  0  8  2]]\n",
      "********\n",
      "Blind well is CHURCHMAN BIBLE, F1 score : 42.6861%\n",
      "(3747, 28) (3747,) (404, 28) (404,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         8\n",
      "          2       0.70      0.57      0.63        56\n",
      "          3       0.57      0.76      0.66        51\n",
      "          4       0.24      0.54      0.33        13\n",
      "          5       0.09      0.03      0.05        30\n",
      "          6       0.53      0.77      0.63        87\n",
      "          7       0.00      0.00      0.00        34\n",
      "          8       0.36      0.56      0.44        75\n",
      "          9       1.00      0.12      0.21        50\n",
      "\n",
      "avg / total       0.49      0.48      0.43       404\n",
      "\n",
      "[[ 0  7  1  0  0  0  0  0  0]\n",
      " [ 0 32 23  0  0  1  0  0  0]\n",
      " [ 0  7 39  0  0  0  0  5  0]\n",
      " [ 0  0  0  7  0  5  0  1  0]\n",
      " [ 0  0  1  3  1 19  0  6  0]\n",
      " [ 0  0  0 10  1 67  0  9  0]\n",
      " [ 0  0  1  7  4  8  0 14  0]\n",
      " [ 0  0  3  2  4 24  0 42  0]\n",
      " [ 0  0  0  0  1  2  0 41  6]]\n",
      "==============================\n",
      "==============================\n",
      "Average  F1-score is 51.9018%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/lorenzoperozzi/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Create a set of unique well names\n",
    "from sklearn import preprocessing\n",
    "\n",
    "names = list(set(training_data[\"Well Name\"]))\n",
    "target_names = ['SS','CsiS','FSiS', 'SiSh','MS','WS','D','PS','BS']\n",
    "#Create a dicitionary of the well datasets, continued from original contest notebook \n",
    "#But perform dropping for each well individually\n",
    "#Maybe not necessary.\n",
    "\n",
    "well_datas = {}\n",
    "for name in names:\n",
    "    well = training_data[training_data[\"Well Name\"]==name] \n",
    "    well_labels = well['Facies'].values.astype(np.int64)\n",
    "    well = well.drop(['Formation', 'Well Name', 'Depth','Facies','FaciesLabels'], axis=1).values\n",
    "    well_datas[name] = [well, well_labels]\n",
    "    \n",
    "    \n",
    "X_data = {}\n",
    "y_data = {}\n",
    "for name, (data, labels) in well_datas.items():\n",
    "    y_data[name] = np.array(labels, dtype=np.int64)\n",
    "    X_data[name] = np.array(data, dtype=np.float32)\n",
    "\n",
    "training_sets = []\n",
    "test_sets = []\n",
    "\n",
    "for i in range(len(names)):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for name, data in X_data.items():\n",
    "        if name is not names[i]:\n",
    "            for row in data:\n",
    "                X_train.append(row)\n",
    "        else:\n",
    "            for row in data:\n",
    "                X_test.append(row)\n",
    "\n",
    "    for name, labels in y_data.items():\n",
    "        if name is not names[i]:\n",
    "            for val in labels:\n",
    "                y_train.append(val)\n",
    "        else:\n",
    "            for val in labels:\n",
    "                y_test.append(val)\n",
    "\n",
    "    X_train = np.array(X_train, dtype=np.float32)\n",
    "    y_train = np.array(y_train, dtype=np.int64).reshape(len(y_train), 1)\n",
    "    y_train = y_train.ravel()\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "    X_test = np.array(X_test, dtype=np.float32)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    y_test = np.array(y_test, dtype=np.int32)\n",
    "    training_sets.append([X_train, y_train, X_test, y_test])\n",
    "    \n",
    "#Use as follows:\n",
    "scores = []\n",
    "for i, (X_train, y_train, X_test, y_test) in enumerate(training_sets):\n",
    "    clf = ensemble.RandomForestClassifier(n_estimators=1000, max_features='auto')\n",
    "#     clf = svm.LinearSVC(class_weight='balanced', tol=1e-03, random_state=42, C=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #Scoring\n",
    "    score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    scores.append(score)\n",
    "    cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "    print('********')\n",
    "    print('Blind well is {0:10}, F1 score : {1:.4%}'.format(names[i],score))\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    print(metrics.classification_report(y_test,y_pred, target_names=target_names))\n",
    "    print(cm)\n",
    "    pass\n",
    "print(\"=\"*30)\n",
    "print(\"=\"*30)\n",
    "print('Average  F1-score is {:.4%}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LUKE G U',\n",
       " 'NOLAN',\n",
       " 'CROSS H CATTLE',\n",
       " 'NEWBY',\n",
       " 'Recruit F9',\n",
       " 'SHRIMPLIN',\n",
       " 'CHURCHMAN BIBLE']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data[training_data['Well Name']=='NOLAN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import cross_validation\n",
    "# from sklearn import tree\n",
    "# from sklearn import svm\n",
    "# from sklearn import ensemble\n",
    "# from sklearn import neighbors\n",
    "# from sklearn import linear_model\n",
    "# from sklearn import metrics\n",
    "# from sklearn import preprocessing\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from classification_utilities import display_cm, display_adj_cm\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# def accuracy(conf):\n",
    "#     total_correct = 0.\n",
    "#     nb_classes = conf.shape[0]\n",
    "#     for i in np.arange(0,nb_classes):\n",
    "#         total_correct += conf[i][i]\n",
    "#     acc = total_correct/sum(sum(conf))\n",
    "#     return acc\n",
    "\n",
    "# adjacent_facies = np.array([[1], [0,2], [1], [4], [3,5], [4,6,7], [5,7], [5,6,8], [6,7]])\n",
    "\n",
    "# def accuracy_adjacent(conf, adjacent_facies):\n",
    "#     nb_classes = conf.shape[0]\n",
    "#     total_correct = 0.\n",
    "#     for i in np.arange(0,nb_classes):\n",
    "#         total_correct += conf[i][i]\n",
    "#         for j in adjacent_facies[i]:\n",
    "#             total_correct += conf[i][j]\n",
    "#     return total_correct / sum(sum(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classifiers = [\n",
    "#     svm.LinearSVC(class_weight='balanced', tol=1e-03, random_state=42, C=10),\n",
    "#     ensemble.RandomForestClassifier(n_estimators=1000),\n",
    "#     ensemble.GradientBoostingClassifier(min_samples_split=1),\n",
    "#     ensemble.BaggingClassifier(),\n",
    "#     XGBClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Logging for Visual Comparison\n",
    "# log_cols=[\"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "# log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     name = clf.__class__.__name__\n",
    "    \n",
    "#     print(\"=\"*30)\n",
    "#     print(name)\n",
    "    \n",
    "#     print('****Results****\\n')\n",
    "#     predicted_labels = clf.predict(X_test)\n",
    "    \n",
    "#     accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "#     print(\"Accuracy: {:.4%}\".format(accuracy))\n",
    "# #     conf = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "# #     print('Optimized facies classification accuracy = %.2f' % accuracy(conf))\n",
    "# #     print('Optimized adjacent facies classification accuracy = %.2f\\n' % accuracy_adjacent(conf, adjacent_facies))\n",
    "    \n",
    "# #     display_adj_cm(conf, facies_labels, adjacent_facies,display_metrics=True, hide_zeros=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     precision = metrics.precision_score(y_test, predicted_labels, average='weighted')\n",
    "#     print(\"Precision: {:.4%}\".format(precision))\n",
    "    \n",
    "#     recall = metrics.recall_score(y_test, predicted_labels, average='weighted')\n",
    "#     print(\"Recall: {:.4%}\".format(recall))\n",
    "    \n",
    "#     f1 = metrics.f1_score(y_test, predicted_labels, average='weighted')\n",
    "#     print(\"F1 score: {:.4%}\".format(f1))\n",
    "    \n",
    "#     print(metrics.classification_report(y_test, predicted_labels, target_names=facies_labels))\n",
    "       \n",
    "#     log_entry = pd.DataFrame([[name, accuracy*100, precision*100, recall*100, f1*100]], columns=log_cols)\n",
    "#     log = log.append(log_entry)\n",
    "    \n",
    "# print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
